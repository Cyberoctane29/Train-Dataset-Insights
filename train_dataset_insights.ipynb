{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Dataset Analysis\n",
    "\n",
    "## **Introduction**\n",
    "In this project, I explore the Train dataset using Pandas and Numpy to gain fundamental insights into passenger demographics and ticket pricing. By analyzing the dataset, the aim is to understand trends related to passenger age distribution, ticket prices, and travel class. \n",
    "\n",
    "The analysis involves various data manipulation techniques, statistical summaries, and indexing methods to uncover key patterns and relationships within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Structure  \n",
    "\n",
    "#### **1. Train Dataset**  \n",
    "This dataset contains information about passengers aboard the Train, including their survival status, personal details, and travel information. It includes the following fields:  \n",
    "\n",
    "- **PassengerId**: A unique identifier for each passenger.  \n",
    "- **Survived**: A binary indicator (0 or 1) where 0 means the passenger did not survive and 1 means the passenger survived.  \n",
    "- **Pclass**: The passenger's class on the train, where 1 is first class, 2 is second class, and 3 is third class.  \n",
    "- **Name**: The full name of the passenger.  \n",
    "- **Sex**: The gender of the passenger (male or female).  \n",
    "- **Age**: The age of the passenger in years.  \n",
    "- **SibSp**: The number of siblings or spouses the passenger was traveling with.  \n",
    "- **Parch**: The number of parents or children the passenger was traveling with.  \n",
    "- **Ticket**: The ticket number assigned to the passenger.  \n",
    "- **Fare**: The fare paid by the passenger for the trip.  \n",
    "- **Cabin**: The cabin number the passenger was assigned to (if available).  \n",
    "- **Embarked**: The port at which the passenger boarded the Train, represented as 'C' for Cherbourg, 'Q' for Queenstown, and 'S' for Southampton.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importing Required Libraries**\n",
    "\n",
    "Before starting the analysis, I first import the necessary libraries to perform the required operations. This includes `Pandas` for data manipulation and `NumPy` for numerical calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loading the Dataset**\n",
    "\n",
    "The dataset containing various passenger details is loaded using `pd.read_csv()`. This allows me to work with the data in a structured format, which will enable further exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset\n",
    "\n",
    "dataframe=pd.read_csv(r\"C:\\Users\\saswa\\Documents\\GitHub\\Train-Dataset-Insights\\Data\\train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "To better understand the structure of the dataset, I display the first 25 records, which provide an overview of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis of Age Column\n",
    "Next, I perform basic statistical operations to gain insights into the distribution of ages among passengers. These include calculating the mean, maximum, minimum, and standard deviation of the age column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Age\n",
    "print(\"Mean Age:\", dataframe['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Age\n",
    "print(\"Max Age:\", dataframe['Age'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum Age\n",
    "print(\"Min Age:\", dataframe['Age'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deviation of Age\n",
    "print(\"Standard Deviation of Age:\", dataframe['Age'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passenger Class Distribution\n",
    "To understand the distribution of passengers across different classes, I use `value_counts()` on the `Pclass` column. This helps me see how many passengers belong to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Pclass'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "Using `describe()`, I generate a comprehensive summary of all numerical columns in the dataset. This gives me an overview of important statistics like mean, standard deviation, min, max, and quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Elderly Passengers in Third Class\n",
    "I filter passengers who are older than 60 years and traveled in third class. This provides insight into the elderly passenger demographic in lower-class sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[(dataframe['Age'] > 60) & (dataframe['Pclass'] == 3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Fare to 2025 Rates\n",
    "Calculating the fare in 2025 by multiplying the original fare by an inflation factor (146.14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['2025_Fare'] = dataframe['Fare'] * 146.14\n",
    "dataframe.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Specific Data Points\n",
    "I demonstrate how to access specific data points using `iloc` and `loc`. Here, I retrieve the third column value from the second row as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieving the third column value of the second row\n",
    "dataframe.iloc[1, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Data by Gender and Passenger Class\n",
    "I group the data by gender and passenger class to analyze the average fare for each category. This helps in understanding payment trends across different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare = dataframe.groupby(['Sex', 'Pclass']).agg({'Fare': ['count', 'sum']})\n",
    "fare['fare_avg'] = fare['Fare']['sum'] / fare['Fare']['count']\n",
    "fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames from Numpy Arrays\n",
    "To demonstrate various methods of creating Pandas DataFrames, I first show how to create a DataFrame from a dictionary. Then, I demonstrate creating a DataFrame from a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from a dictionary\n",
    "data = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from a NumPy array\n",
    "data1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "df1 = pd.DataFrame(data=data1, columns=['a', 'b', 'c'], index=['x', 'y', 'z'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative DataFrame Creation Method\n",
    "I show another method for creating a DataFrame using NumPy arrays to further illustrate the flexibility of Pandas for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "                   columns=['a', 'b', 'c'], index=['x', 'y', 'z'])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data Types\n",
    "To better understand the dataset, I check the data types of specific elements. This helps me ensure that the data is in the correct format for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking type of a single row\n",
    "print(type(dataframe.iloc[0]))\n",
    "\n",
    "# Checking type of the 'Name' column\n",
    "print(type(dataframe['Name']))  # or df3.Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the Train Dataset\n",
    "Reassigning the dataset for further exploration, I display the first few rows, check the column names, and get general information about the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataframe\n",
    "train.head()\n",
    "\n",
    "train.columns  # Viewing column names\n",
    "train.shape    # Checking dataset dimensions\n",
    "train.info()   # Getting dataset info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Specific Columns\n",
    "I demonstrate different ways of extracting the 'Age' column. This provides insight into how to handle individual columns in a dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['Age']\n",
    "train.Age\n",
    "train[['Name', 'Age']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Rows and Columns\n",
    "Using both `iloc` and `loc`, I show how to access specific rows and values. This is helpful for precise data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting a single row\n",
    "train.iloc[0]\n",
    "\n",
    "# Extracting multiple rows\n",
    "train.iloc[[0]]\n",
    "train.iloc[0:3]\n",
    "\n",
    "# Extracting specific columns for the first three rows\n",
    "train.iloc[0:3, [3, 4]]\n",
    "train.iloc[:, [3]]\n",
    "train.iloc[0, 3]\n",
    "train.loc[0:3, ['Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a New Column\n",
    "I add a new column, `Age_plus_100`, which adds 100 years to each passenger's age for a hypothetical scenario. This shows how to create and manipulate new columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['Age_plus_100'] = train['Age'] + 100\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "Through the analysis of the Train dataset, I explored key insights into passenger demographics, travel class distribution, ticket pricing, and fare trends. Using Pandas for data manipulation and statistical analysis, I uncovered patterns such as age distribution, the impact of passenger class on fare pricing, and ticket cost differences when adjusted for inflation. This project highlighted the importance of data wrangling and statistical summaries in extracting meaningful insights.\n",
    "\n",
    "The combination of Pandas for data processing and NumPy for numerical computations enabled efficient analysis, providing a deeper understanding of passengers' characteristics. These insights can inform service improvements, fare adjustments, and targeted marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Application of Insights**\n",
    "\n",
    "The insights from this analysis of the Train dataset have practical applications in the travel industry, economics, and customer segmentation. By understanding passenger distribution and fare correlations, businesses can optimize pricing, tailor marketing, and enhance services for specific groups. This also informs operational decisions, such as prioritizing upgrades for elderly travelers in third class, and highlights opportunities for inclusive pricing models.\n",
    "\n",
    "This analysis lays the foundation for further exploration of passenger behavior, travel trends, and fare structures, guiding future modeling and enabling data-driven decisions to refine strategies and improve services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Next Steps**\n",
    "\n",
    "- **Deeper Demographic Analysis**: Explore additional factors like marital status or family size and their impact on ticket pricing.\n",
    "- **Expand Dataset**: Include data from similar travel datasets (e.g., other trains) for comparative insights.\n",
    "- **Predictive Modeling**: Develop models to forecast fare pricing based on features like class and age, optimizing demand forecasting.\n",
    "- **Visualizing Trends**: Create visualizations for age distribution, fare trends, and class demographics to simplify data interpretation.\n",
    "  \n",
    "By addressing these steps, the analysis can be expanded to provide more actionable insights for businesses and stakeholders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
